# HaikuGraph Project Documentation
**Natural Language Data Assistant with Interactive Visualizations**

---

## Table of Contents
1. [Project Overview](#project-overview)
2. [Architecture](#architecture)
3. [Implementation Task List](#implementation-task-list)
4. [System Flow Diagrams](#system-flow-diagrams)
5. [What We Showcase](#what-we-showcase)
6. [Solution Differentiation](#solution-differentiation)
7. [Pros and Cons Analysis](#pros-and-cons-analysis)

---

## Project Overview

HaikuGraph is a natural language data assistant that allows users to query their data using plain English. The system translates questions into SQL, executes them against a DuckDB database, and presents results through interactive visualizations with full transparency into the query planning and execution process.

### Key Features
- ğŸ—£ï¸ **Natural Language Queries**: Ask questions in plain English
- ğŸ“Š **Rich Visualizations**: Auto-generated charts, tables, and number displays
- ğŸ” **Full Transparency**: View intent classification, query plans, and generated SQL
- ğŸ“ˆ **Smart Comparisons**: Automatic period-over-period analysis
- ğŸ¨ **Interactive UI**: Filter, sort, paginate, zoom, and export data
- ğŸ§ª **Data Quality Insights**: Surface and visualize NULL/missing data

---

## Architecture

### High-Level System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND                             â”‚
â”‚                   React + Vite + Recharts                   â”‚
â”‚                   (http://localhost:5173)                   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  User Interface                                      â”‚  â”‚
â”‚  â”‚  â€¢ Question input with examples                      â”‚  â”‚
â”‚  â”‚  â€¢ Answer display with metadata                      â”‚  â”‚
â”‚  â”‚  â€¢ Comparison cards (period-over-period)             â”‚  â”‚
â”‚  â”‚  â€¢ Interactive visualizations (charts/tables)        â”‚  â”‚
â”‚  â”‚  â€¢ Explainability tabs (Intent/Plan/SQL/Raw Data)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†• HTTP REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BACKEND                              â”‚
â”‚                    FastAPI + Python                         â”‚
â”‚                   (http://localhost:8000)                   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  API Layer (FastAPI)                                 â”‚  â”‚
â”‚  â”‚  â€¢ POST /ask - Main query endpoint                   â”‚  â”‚
â”‚  â”‚  â€¢ GET /health - Health check                        â”‚  â”‚
â”‚  â”‚  â€¢ CORS middleware for dev                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â†“                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Processing Pipeline                                 â”‚  â”‚
â”‚  â”‚  1. Intent Classification (LLM + Rules)              â”‚  â”‚
â”‚  â”‚  2. Query Planning (Ollama)                          â”‚  â”‚
â”‚  â”‚  3. SQL Generation & Execution (DuckDB)              â”‚  â”‚
â”‚  â”‚  4. Comparison Extraction                            â”‚  â”‚
â”‚  â”‚  5. Narration (Ollama)                               â”‚  â”‚
â”‚  â”‚  6. Visualization Hints                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DATA LAYER                              â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   DuckDB     â”‚ â†â”€â”€ â”‚ Excel Files  â”‚ â†â”€â”€ â”‚  CSV Data  â”‚ â”‚
â”‚  â”‚  (In-Memory) â”‚     â”‚ (.xlsx/.xls) â”‚     â”‚            â”‚ â”‚
â”‚  â”‚              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”‚ â€¢ test_1_1   â”‚                                          â”‚
â”‚  â”‚ â€¢ test_2_1   â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ â€¢ test_3_1   â”‚ â†â”€â”€ â”‚ Profile JSON â”‚                    â”‚
â”‚  â”‚ â€¢ test_4_1   â”‚     â”‚ (Metadata)   â”‚                    â”‚
â”‚  â”‚ â€¢ test_5_1   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                       â”‚ Data Cards   â”‚                     â”‚
â”‚                       â”‚ (Semantics)  â”‚                     â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

#### Backend
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Web Framework | FastAPI | Modern, async Python API |
| Server | Uvicorn | ASGI server with hot reload |
| Database | DuckDB | In-process analytical DB |
| LLM Runtime | Ollama | Local LLM for planning/narration |
| Data Validation | Pydantic | Request/response schemas |

#### Frontend
| Component | Technology | Purpose |
|-----------|-----------|---------|
| UI Framework | React 18 | Component-based UI |
| Build Tool | Vite | Fast dev server & bundler |
| Charts | Recharts | Composable chart library |
| Icons | Lucide React | Icon components |
| State | React Hooks | Local state management |

---

## Implementation Task List

### Phase 1: Foundation & Data Ingestion
- [x] **Data Ingestion System**
  - Excel/CSV file reader with auto-fallback to string mode
  - DuckDB table creation with sanitized naming
  - Automatic type inference with error recovery
  - Profile generation with statistics

- [x] **Schema Analysis**
  - Column type detection (numeric, date, string, identifier)
  - Null percentage and distinct count analysis
  - Semantic hints (timestamp, money, status columns)
  - Table grain and primary key detection

- [x] **Data Cards Generation**
  - Table cards with suggested metrics
  - Column cards with semantic annotations
  - Relation cards for potential joins
  - Index creation for fast lookup

### Phase 2: Query Processing Pipeline
- [x] **Intent Classification**
  - Rule-based classifier for common patterns
  - LLM fallback for ambiguous cases
  - Confidence scoring and rationale
  - Comparison detection

- [x] **Query Planning**
  - LLM-based plan generation (Ollama)
  - Subquestion decomposition
  - Constraint extraction (time, filters)
  - Table and column selection

- [x] **SQL Generation**
  - Dynamic SQL builder from plan
  - Aggregation support (SUM, COUNT, AVG, MIN, MAX)
  - GROUP BY with time bucketing
  - JOIN path resolution
  - Type casting (VARCHARâ†’TIMESTAMP, VARCHARâ†’DOUBLE)

- [x] **Execution & Results**
  - DuckDB query execution
  - Error handling and retries
  - Result formatting with preview rows
  - Metadata collection (timing, row counts)

### Phase 3: Advanced Features
- [x] **Comparison Extraction**
  - Period-over-period detection
  - Delta and percentage calculation
  - Normalized comparison structure
  - Direction indicators (up/down/flat)

- [x] **Narration**
  - LLM-based result explanation
  - Context-aware language generation
  - Comparison-aware narratives
  - Human-readable formatting

- [x] **Visualization Hints**
  - Shape analysis (rows, columns, types)
  - Auto-detection of chart types
  - Axis and units inference
  - Display hint generation (number/bar/line/table)

### Phase 4: Web UI Development
- [x] **Basic UI Components**
  - Question input form
  - Demo question buttons
  - Answer display card
  - Loading states and error handling

- [x] **Visualization Components**
  - Number display for single values
  - Bar charts for grouped metrics
  - Line charts for time series
  - Data tables for multi-column results

- [x] **Comparison UI**
  - Side-by-side value display
  - Delta and percentage badges
  - Direction indicators with icons
  - Color-coded changes

- [x] **Explainability Interface**
  - Collapsible details section
  - Tabbed navigation (Intent/Plan/SQL/Metadata)
  - JSON pretty-printing
  - Execution timing display

### Phase 5: Interactive Enhancements
- [x] **Interactive Charts**
  - Brush component for zoom/pan
  - Clickable legend to toggle series
  - Custom tooltips with formatting
  - Export to SVG functionality
  - NULL value handling with "(No data)" label

- [x] **Advanced Tables**
  - Pagination (10/25/50/100 rows)
  - Column sorting (asc/desc)
  - Column filtering with search
  - Export to CSV
  - First/Prev/Next/Last navigation
  - Row count display
  - NULL value highlighting

- [x] **Raw Data Tab**
  - Complete preview_rows JSON display
  - Status and column metadata
  - Row count badges
  - Debugging transparency

### Phase 6: Data Quality & Testing
- [x] **Data Quality Detection**
  - NULL percentage analysis
  - Timestamp validation tests
  - VARCHARâ†’TIMESTAMP casting
  - NULLS LAST ordering in GROUP BY

- [x] **Comprehensive Test Suite**
  - Timestamp aggregation tests (MIN/MAX with NULLs)
  - Time grouping tests (month bucketing)
  - Data quality validation tests
  - Aggregation pattern tests
  - 9 tests covering edge cases

- [x] **Frontend NULL Handling**
  - Display "(No data)" for NULL values
  - Gray italic styling for missing data
  - Chart transformation to label NULLs
  - Table cell special rendering

### Phase 7: Developer Experience
- [x] **Unified Startup Script**
  - Single `run.sh` to start both servers
  - Automatic dependency installation
  - Process cleanup on exit
  - Log file redirection

- [x] **Documentation**
  - Architecture diagrams
  - API documentation
  - Component breakdown
  - Usage examples
  - Data quality insights report

---

## System Flow Diagrams

### 1. End-to-End Query Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     USER     â”‚
â”‚ "oldest      â”‚
â”‚ transaction?"â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“ HTTP POST /ask
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND PIPELINE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  Step 1: INTENT CLASSIFICATION                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Input: "oldest transaction?"                   â”‚    â”‚
â”‚  â”‚ Classifier: Rule-based + LLM                    â”‚    â”‚
â”‚  â”‚ Output: {                                       â”‚    â”‚
â”‚  â”‚   "type": "metric",                             â”‚    â”‚
â”‚  â”‚   "confidence": 0.85,                           â”‚    â”‚
â”‚  â”‚   "rationale": "MIN aggregation detected"       â”‚    â”‚
â”‚  â”‚ }                                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                       â†“                                  â”‚
â”‚  Step 2: PLAN GENERATION                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Input: Question + Schema + Intent              â”‚    â”‚
â”‚  â”‚ Planner: Ollama LLM                             â”‚    â”‚
â”‚  â”‚ Output: {                                       â”‚    â”‚
â”‚  â”‚   "subquestions": [{                            â”‚    â”‚
â”‚  â”‚     "tables": ["test_2_1"],                     â”‚    â”‚
â”‚  â”‚     "columns": ["payment_created_at"],          â”‚    â”‚
â”‚  â”‚     "aggregations": [{                          â”‚    â”‚
â”‚  â”‚       "agg": "MIN",                              â”‚    â”‚
â”‚  â”‚       "col": "payment_created_at"                â”‚    â”‚
â”‚  â”‚     }]                                           â”‚    â”‚
â”‚  â”‚   }]                                             â”‚    â”‚
â”‚  â”‚ }                                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                       â†“                                  â”‚
â”‚  Step 3: SQL GENERATION & EXECUTION                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Generated SQL:                                  â”‚    â”‚
â”‚  â”‚ SELECT MIN(TRY_CAST("test_2_1"."payment_       â”‚    â”‚
â”‚  â”‚   created_at" AS TIMESTAMP)) AS                 â”‚    â”‚
â”‚  â”‚   "min_payment_created_at"                      â”‚    â”‚
â”‚  â”‚ FROM "test_2_1"                                 â”‚    â”‚
â”‚  â”‚                                                  â”‚    â”‚
â”‚  â”‚ DuckDB Execution:                               â”‚    â”‚
â”‚  â”‚ Result: [('2025-05-22 22:30:57.548+00:00',)]   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                       â†“                                  â”‚
â”‚  Step 4: NARRATION                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Input: Question + Intent + Results              â”‚    â”‚
â”‚  â”‚ Narrator: Ollama LLM                            â”‚    â”‚
â”‚  â”‚ Output: "The oldest transaction was created     â”‚    â”‚
â”‚  â”‚          on May 22, 2025 at 22:30:57 UTC."     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                       â†“                                  â”‚
â”‚  Step 5: VISUALIZATION HINTS                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Analysis: 1 row, 1 column, timestamp type       â”‚    â”‚
â”‚  â”‚ Hint: {                                         â”‚    â”‚
â”‚  â”‚   "display_hint": "number",                     â”‚    â”‚
â”‚  â”‚   "units": null                                 â”‚    â”‚
â”‚  â”‚ }                                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“ JSON Response
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FRONTEND                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Render Components:                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Answer Card                                     â”‚   â”‚
â”‚  â”‚ "The oldest transaction was created on..."      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Visualization (Number Display)                  â”‚   â”‚
â”‚  â”‚ 2025-05-22 22:30:57.548000+00:00                â”‚   â”‚
â”‚  â”‚ min_payment_created_at                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ View Details (Collapsed)                        â”‚   â”‚
â”‚  â”‚ â€¢ Intent: metric (85% confidence)               â”‚   â”‚
â”‚  â”‚ â€¢ Plan: 1 subquestion, 1 table                  â”‚   â”‚
â”‚  â”‚ â€¢ SQL: SELECT MIN(TRY_CAST...                   â”‚   â”‚
â”‚  â”‚ â€¢ Raw Data: [{"min_payment_created_at": ...}]   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Data Quality Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             DATA QUALITY DETECTION                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 1: IDENTIFY NULL DATA
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SQL: SELECT COUNT(*),                      â”‚
â”‚      COUNT(payment_created_at),            â”‚
â”‚      COUNT(*) - COUNT(payment_created_at)  â”‚
â”‚      FROM test_2_1                         â”‚
â”‚                                            â”‚
â”‚ Result:                                    â”‚
â”‚ Total: 76,583                              â”‚
â”‚ Non-NULL: 1,715                            â”‚
â”‚ NULL: 74,868                               â”‚
â”‚ NULL %: 97.8%                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“

Step 2: HANDLE IN SQL GENERATION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Use TRY_CAST for VARCHARâ†’TIMESTAMP       â”‚
â”‚ â€¢ Add NULLS LAST to ORDER BY               â”‚
â”‚ â€¢ Keep NULL in GROUP BY (separate bucket)  â”‚
â”‚                                            â”‚
â”‚ Example:                                   â”‚
â”‚ SELECT                                     â”‚
â”‚   date_trunc('month',                      â”‚
â”‚     TRY_CAST(payment_created_at           â”‚
â”‚       AS TIMESTAMP)) as month,            â”‚
â”‚   COUNT(*) as count                       â”‚
â”‚ FROM test_2_1                              â”‚
â”‚ GROUP BY month                             â”‚
â”‚ ORDER BY month NULLS LAST                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“

Step 3: VISUALIZE WITH NULL BUCKET
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chart Data:                                â”‚
â”‚ â€¢ Month 1: 1,152 records                   â”‚
â”‚ â€¢ Month 5: 12 records                      â”‚
â”‚ â€¢ Month 9: 109 records                     â”‚
â”‚ â€¢ ...                                      â”‚
â”‚ â€¢ (No data): 74,868 records â† Majority!    â”‚
â”‚                                            â”‚
â”‚ Frontend Transformation:                   â”‚
â”‚ â€¢ NULL â†’ "(No data)"                       â”‚
â”‚ â€¢ Gray italic styling                      â”‚
â”‚ â€¢ Separate bar in chart                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“

Step 4: SURFACE IN UI
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ Bar Chart: Transactions by Month   â”‚    â”‚
â”‚ â”‚                                    â”‚    â”‚
â”‚ â”‚  â–ˆâ–ˆâ–ˆâ–ˆ 1,152 (Month 1)              â”‚    â”‚
â”‚ â”‚  â–ˆâ–ˆ 348 (Month 12)                 â”‚    â”‚
â”‚ â”‚  â–ˆ 109 (Month 9)                   â”‚    â”‚
â”‚ â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 74,868 (No data) âš ï¸  â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                            â”‚
â”‚ Raw Data Tab Shows:                        â”‚
â”‚ â€¢ "month": null                            â”‚
â”‚ â€¢ "count": 74868                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Interactive Visualization Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          INTERACTIVE TABLE FEATURES            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Initial Load (100 rows from DB)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ useTableControls Hook                      â”‚
â”‚ â€¢ currentPage = 1                          â”‚
â”‚ â€¢ pageSize = 10                            â”‚
â”‚ â€¢ sortColumn = null                        â”‚
â”‚ â€¢ sortDirection = 'asc'                    â”‚
â”‚ â€¢ filters = {}                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
USER INTERACTIONS:
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. FILTER: User types "Alice" in customer â”‚
â”‚    â†’ filters = { customer: "Alice" }       â”‚
â”‚    â†’ filteredData = data.filter(...)       â”‚
â”‚    â†’ currentPage reset to 1                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. SORT: User clicks "amount" header      â”‚
â”‚    â†’ sortColumn = "amount"                 â”‚
â”‚    â†’ sortDirection = "asc"                 â”‚
â”‚    â†’ sortedData = [...filteredData].sort()â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. PAGINATE: Show 10 rows at a time       â”‚
â”‚    â†’ start = (currentPage - 1) * pageSize  â”‚
â”‚    â†’ end = start + pageSize                â”‚
â”‚    â†’ paginatedData = sortedData.slice(...) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. RENDER TABLE                            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ customer â–²  amount  date             â”‚  â”‚
â”‚ â”‚ [Search..]  [Search] [Search]        â”‚  â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚
â”‚ â”‚ Alice       $1,000   2025-01-15      â”‚  â”‚
â”‚ â”‚ Alice       $2,000   2025-02-20      â”‚  â”‚
â”‚ â”‚ ...         ...      ...             â”‚  â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚
â”‚ â”‚ Showing 1-10 of 15    [Export CSV]   â”‚  â”‚
â”‚ â”‚ [<<] [<] Page 1 of 2 [>] [>>]        â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. EXPORT: User clicks "Export CSV"       â”‚
â”‚    â†’ exportToCSV(allFilteredData, ...)    â”‚
â”‚    â†’ Browser downloads filtered_data.csv   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## What We Showcase

### 1. **Natural Language to SQL Translation**
- **Challenge**: Bridge the gap between human language and database queries
- **Our Approach**: Multi-stage pipeline with intent classification, semantic planning, and validated SQL generation
- **Result**: Users can ask "Show me revenue by customer" without knowing SQL syntax

### 2. **Full Transparency & Explainability**
- **Challenge**: Black-box AI systems lack trust
- **Our Approach**: Every query shows its reasoning:
  - Intent classification with confidence scores
  - Complete query plan with subquestions
  - Generated SQL visible to users
  - Raw data tab for verification
- **Result**: Users understand how answers were derived and can debug issues

### 3. **Smart Data Quality Handling**
- **Challenge**: Real-world data is messy (97.8% NULL timestamps in our case!)
- **Our Approach**: 
  - Don't filter outâ€”show NULLs as "(No data)" buckets
  - Surface data quality issues visually
  - Add tests to detect and report problems
- **Result**: Users see the true state of their data and can take action

### 4. **Interactive Visualizations**
- **Challenge**: Static charts don't allow exploration
- **Our Approach**: Full interactivity:
  - Zoom/pan on charts
  - Sort/filter/paginate tables
  - Export data in multiple formats
  - Toggle series visibility
- **Result**: Users can explore data beyond the initial answer

### 5. **Type Safety & Error Recovery**
- **Challenge**: Data types in Excel/CSV are unreliable (VARCHAR timestamps)
- **Our Approach**:
  - Intelligent type casting (TRY_CAST)
  - Auto-fallback to string mode on ingestion errors
  - Semantic column detection (timestamps, currency)
- **Result**: Robust system that handles messy real-world data

### 6. **Local-First Architecture**
- **Challenge**: Privacy and latency concerns with cloud LLMs
- **Our Approach**:
  - Local Ollama for LLM inference
  - DuckDB for in-process analytics
  - No data leaves the machine
- **Result**: Fast, private, and offline-capable

### 7. **Comparison Intelligence**
- **Challenge**: Period-over-period analysis requires domain logic
- **Our Approach**:
  - Automatic detection of comparison queries
  - Normalized comparison structure
  - Delta and percentage calculation
  - Visual comparison cards
- **Result**: Users get instant insights on trends

---

## Solution Differentiation

### How HaikuGraph is Different

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TRADITIONAL APPROACHES                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  1. Manual SQL Writing                                  â”‚
â”‚     â€¢ Users must know SQL syntax                        â”‚
â”‚     â€¢ Slow iteration for exploratory analysis           â”‚
â”‚     â€¢ Error-prone for complex queries                   â”‚
â”‚                                                         â”‚
â”‚  2. BI Tools (Tableau, Power BI)                        â”‚
â”‚     â€¢ Drag-and-drop interface                           â”‚
â”‚     â€¢ Requires upfront data modeling                    â”‚
â”‚     â€¢ Limited natural language support                  â”‚
â”‚     â€¢ Expensive licensing                               â”‚
â”‚                                                         â”‚
â”‚  3. Cloud AI SQL Assistants (BigQuery, Snowflake)      â”‚
â”‚     â€¢ Natural language interface âœ“                      â”‚
â”‚     â€¢ But: Data must be in cloud                        â”‚
â”‚     â€¢ But: Black-box reasoning                          â”‚
â”‚     â€¢ But: Pay-per-query                                â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          VS

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   HAIKUGRAPH                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  âœ… Natural Language Interface                          â”‚
â”‚     â€¢ Plain English questions                           â”‚
â”‚     â€¢ No SQL knowledge required                         â”‚
â”‚     â€¢ Instant results                                   â”‚
â”‚                                                         â”‚
â”‚  âœ… Full Transparency                                   â”‚
â”‚     â€¢ See intent classification                         â”‚
â”‚     â€¢ View query plan                                   â”‚
â”‚     â€¢ Inspect generated SQL                             â”‚
â”‚     â€¢ Verify raw data                                   â”‚
â”‚                                                         â”‚
â”‚  âœ… Local & Private                                     â”‚
â”‚     â€¢ Data never leaves your machine                    â”‚
â”‚     â€¢ Local LLM (Ollama)                                â”‚
â”‚     â€¢ In-process database (DuckDB)                      â”‚
â”‚     â€¢ Offline-capable                                   â”‚
â”‚                                                         â”‚
â”‚  âœ… Smart Data Quality                                  â”‚
â”‚     â€¢ Surfaces NULL/missing data                        â”‚
â”‚     â€¢ Handles messy real-world data                     â”‚
â”‚     â€¢ Type inference and casting                        â”‚
â”‚     â€¢ Test-driven quality checks                        â”‚
â”‚                                                         â”‚
â”‚  âœ… Interactive Exploration                             â”‚
â”‚     â€¢ Zoom/filter/sort on the fly                       â”‚
â”‚     â€¢ Export to CSV/SVG                                 â”‚
â”‚     â€¢ Pagination for large datasets                     â”‚
â”‚     â€¢ Real-time data transformation                     â”‚
â”‚                                                         â”‚
â”‚  âœ… No Upfront Modeling                                 â”‚
â”‚     â€¢ Auto-ingest from Excel/CSV                        â”‚
â”‚     â€¢ Auto-generate data cards                          â”‚
â”‚     â€¢ Schema-on-read                                    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Unique Selling Points

1. **Transparency-First Design**
   - Unlike black-box AI tools, every decision is explainable
   - Users see the "why" behind every answer
   - Builds trust through visibility

2. **Data Quality as First-Class Citizen**
   - Most tools hide NULLs; we surface them
   - Comprehensive test suite for edge cases
   - Visual indicators for missing data

3. **Local-First with Enterprise Potential**
   - Start local for privacy/speed
   - Architecture supports scale-out (see ARCHITECTURE.md)
   - No vendor lock-in

4. **Developer-Friendly**
   - Full test coverage
   - Clear separation of concerns
   - Easy to extend and customize

5. **Real-World Data Tolerance**
   - Handles VARCHAR timestamps
   - Auto-fallback on type errors
   - Graceful degradation

---

## Pros and Cons Analysis

### âœ… PROS

#### Technical Strengths
1. **Clean Architecture**
   - Modular pipeline (Intent â†’ Plan â†’ Execute â†’ Narrate)
   - Same backend for CLI and UI
   - Easy to test and maintain
   - Clear separation of concerns

2. **Rich Type System**
   - Pydantic models for validation
   - Type hints throughout Python code
   - React PropTypes for components
   - Catches errors early

3. **Comprehensive Testing**
   - 9 data quality tests
   - Edge case coverage (NULL handling)
   - Timestamp validation
   - Aggregation pattern tests

4. **Performance**
   - In-process DuckDB (no network overhead)
   - Local LLM (200-500ms latency)
   - Efficient SQL generation
   - Preview-based pagination

5. **User Experience**
   - Intuitive natural language interface
   - Rich visualizations auto-generated
   - Full transparency (intent/plan/SQL)
   - Interactive exploration tools

#### Business Strengths
1. **Privacy & Security**
   - All data stays local
   - No cloud dependencies
   - GDPR/HIPAA friendly
   - Audit trail built-in

2. **Cost Effective**
   - No per-query fees
   - No data egress charges
   - Open-source components
   - Self-hosted option

3. **Rapid Setup**
   - Single command data ingestion
   - Auto-schema detection
   - No upfront modeling required
   - Works with existing Excel/CSV files

### âŒ CONS

#### Technical Limitations
1. **Scalability Constraints**
   - In-process DuckDB limits concurrent users (1-5)
   - Single LLM instance (no load balancing)
   - No caching layer in POC
   - Not tested with >100GB datasets
   - **Mitigation**: Architecture supports scale-out (see ARCHITECTURE.md production design)

2. **LLM Dependency**
   - Requires Ollama installation
   - LLM accuracy not 100%
   - Latency varies by query complexity
   - May hallucinate on ambiguous questions
   - **Mitigation**: Fallback to simpler models, manual SQL override

3. **Limited Query Complexity**
   - No subqueries in POC
   - Complex JOINs not fully tested
   - Window functions not supported
   - No recursive CTEs
   - **Mitigation**: Roadmap includes advanced SQL features

4. **Data Type Handling**
   - All ingested as VARCHAR (DuckDB limitation)
   - Requires TRY_CAST at query time
   - Date parsing can be ambiguous
   - No schema enforcement
   - **Mitigation**: Future: support proper types on ingestion

5. **Error Recovery**
   - LLM failures stop the pipeline
   - No retry logic for transient errors
   - User must rephrase on failure
   - **Mitigation**: Add retry with exponential backoff

#### Business Limitations
1. **Enterprise Features Missing**
   - No authentication/authorization
   - No multi-tenancy
   - No audit logs
   - No role-based access control
   - **Mitigation**: Roadmap includes enterprise features

2. **Integration Gaps**
   - Only supports Excel/CSV (no databases)
   - No real-time data sources
   - No API for external apps
   - No Slack/Teams bot
   - **Mitigation**: API-first design allows easy integration

3. **Operational Complexity**
   - Requires Ollama setup
   - Manual model management
   - No monitoring dashboard
   - No alerting system
   - **Mitigation**: Docker image for easy deployment

4. **Documentation Gaps**
   - No video tutorials
   - Limited troubleshooting guide
   - No architecture decision records (ADRs)
   - **Mitigation**: Comprehensive markdown docs added

5. **Community & Support**
   - No community forum
   - No commercial support option
   - Single maintainer risk
   - **Mitigation**: Open-source model encourages contributions

### ğŸ”„ TRADE-OFFS MADE

1. **Local LLM vs Cloud LLM**
   - **Chose**: Local (Ollama)
   - **Why**: Privacy, cost, offline capability
   - **Cost**: Slightly lower accuracy, higher setup complexity

2. **In-Process DB vs Client-Server**
   - **Chose**: In-process (DuckDB)
   - **Why**: Simplicity, performance for analytics
   - **Cost**: Limited concurrency, no true multi-user

3. **Transparency vs Simplicity**
   - **Chose**: Transparency (show all reasoning)
   - **Why**: Build trust, enable debugging
   - **Cost**: More UI complexity, potential information overload

4. **Auto-Infer vs User-Define Schema**
   - **Chose**: Auto-infer
   - **Why**: Faster setup, less user burden
   - **Cost**: Less control, potential type mismatches

5. **React vs Server-Side Rendering**
   - **Chose**: React SPA
   - **Why**: Rich interactivity, modern developer experience
   - **Cost**: Larger bundle size, SEO challenges

---

## Future Roadmap

### Short Term (1-3 months)
- [ ] Add authentication (OAuth2)
- [ ] Implement caching (Redis)
- [ ] Support PostgreSQL/MySQL ingestion
- [ ] Add monitoring dashboard
- [ ] Docker image for easy deployment

### Medium Term (3-6 months)
- [ ] Multi-tenancy support
- [ ] Advanced SQL features (subqueries, CTEs, window functions)
- [ ] Real-time data sources
- [ ] Slack/Teams integration
- [ ] Mobile-responsive UI

### Long Term (6-12 months)
- [ ] Horizontal scaling architecture
- [ ] Cloud-native deployment option
- [ ] Enterprise features (RBAC, audit logs)
- [ ] ML-based query optimization
- [ ] Natural language follow-ups

---

## Conclusion

HaikuGraph demonstrates a **transparency-first, local-first, data-quality-aware** approach to natural language data querying. By combining modern LLMs with robust SQL generation and interactive visualizations, we provide an intuitive yet powerful tool for data exploration.

Our key differentiators are:
1. **Full transparency** into AI reasoning
2. **Local-first** for privacy and speed
3. **Data quality** as a first-class concern
4. **Interactive exploration** beyond static answers

While we have limitations (scalability, LLM dependency, enterprise features), our architecture is designed for growth, and our open approach encourages community contributions.

**HaikuGraph is not just a query toolâ€”it's a data conversation platform.**

---

## Getting Started

```bash
# 1. Ingest your data
haikugraph ingest --data-dir ./data

# 2. Start the application
./run.sh

# 3. Open http://localhost:5173 and start asking questions!
```

For detailed setup instructions, see `QUICK_START.md`.

For API documentation, see `WEB_UI_README.md`.

For test suite details, see `VISUALIZATION_IMPROVEMENTS.md`.

"""A7: Planner Correctness Tests.

This module validates that the planner emits semantically correct, schema-valid
plan JSON for key query types using deterministic LLM mocking.
"""

import json
from unittest.mock import patch

import pytest

from haikugraph.planning.llm_planner import generate_or_patch_plan
from haikugraph.planning.schema import validate_plan_or_raise, Plan
from haikugraph.planning.intent import Intent, IntentType


# ============================================================================
# Helper Functions
# ============================================================================

def _fake_llm_return(plan_dict: dict) -> str:
    """Convert plan dict to JSON string for mocking LLM responses."""
    return json.dumps(plan_dict, indent=2)


def _mock_intent(intent_type: IntentType = IntentType.METRIC) -> Intent:
    """Create a mock intent for testing.
    
    Args:
        intent_type: Type of intent to mock
    
    Returns:
        Mock Intent object
    """
    return Intent(type=intent_type, confidence=0.95, signals=[intent_type.value])


def _assert_only_known_top_level_keys(plan: dict, allowed_extras: set[str] | None = None) -> None:
    """Assert plan only contains known top-level keys plus allowed extras.
    
    Prevents tests from accidentally validating fields that aren't actually used.
    
    Args:
        plan: Plan dict to validate
        allowed_extras: Additional keys allowed beyond the schema (e.g., {"row_limit"})
    """
    allowed_extras = allowed_extras or set()
    
    # Get known keys from Plan schema
    known_keys = set(Plan.model_fields.keys())
    all_allowed = known_keys | allowed_extras
    
    actual_keys = set(plan.keys())
    unknown_keys = actual_keys - all_allowed
    
    assert not unknown_keys, (
        f"Plan contains unexpected top-level keys: {unknown_keys}. "
        f"Known keys: {sorted(known_keys)}, Allowed extras: {sorted(allowed_extras)}"
    )


def _assert_has_pure_aggregation(plan: dict) -> None:
    """Assert plan has aggregations without group_by (pure aggregate like SUM)."""
    assert "subquestions" in plan, "Plan must have subquestions"
    
    # At least one subquestion should have pure aggregation
    found_pure_agg = False
    for sq in plan["subquestions"]:
        if sq.get("aggregations") and not sq.get("group_by"):
            found_pure_agg = True
            assert len(sq["aggregations"]) > 0, f"Subquestion {sq['id']} has empty aggregations"
            # Verify aggregation structure
            for agg in sq["aggregations"]:
                assert "agg" in agg, f"Aggregation missing 'agg' field: {agg}"
                assert "col" in agg, f"Aggregation missing 'col' field: {agg}"
            break
    
    assert found_pure_agg, "Plan must have at least one pure aggregation (aggregations without group_by)"


def _assert_has_grouped_aggregation(plan: dict) -> None:
    """Assert plan has group_by with non-empty aggregations."""
    assert "subquestions" in plan, "Plan must have subquestions"
    
    found_grouped_agg = False
    for sq in plan["subquestions"]:
        if sq.get("group_by") and sq.get("aggregations"):
            found_grouped_agg = True
            assert len(sq["group_by"]) > 0, f"Subquestion {sq['id']} has empty group_by"
            assert len(sq["aggregations"]) > 0, f"Subquestion {sq['id']} has empty aggregations"
            # Verify aggregation structure
            for agg in sq["aggregations"]:
                assert "agg" in agg, f"Aggregation missing 'agg' field: {agg}"
                assert "col" in agg, f"Aggregation missing 'col' field: {agg}"
            break
    
    assert found_grouped_agg, "Plan must have at least one grouped aggregation (group_by + aggregations)"


def _assert_has_time_constraint(plan: dict, require_scoped: bool = False) -> None:
    """Assert plan has time constraint, optionally requires at least one scoped constraint.
    
    Args:
        require_scoped: If True, requires at least one time constraint with applies_to.
                        If False, just requires at least one time constraint.
    """
    assert "constraints" in plan, "Plan must have constraints"
    assert len(plan["constraints"]) > 0, "Plan must have at least one constraint"
    
    found_time_constraint = False
    found_scoped_time_constraint = False
    
    for constraint in plan["constraints"]:
        if constraint.get("type") == "time":
            found_time_constraint = True
            if constraint.get("applies_to"):
                found_scoped_time_constraint = True
    
    assert found_time_constraint, "Plan must have at least one time constraint"
    
    if require_scoped:
        assert found_scoped_time_constraint, "Plan must have at least one scoped time constraint (with applies_to)"


def _assert_is_comparison(plan: dict) -> None:
    """Assert plan is a comparison with 2 subquestions and scoped constraints.
    
    Validates:
    - Exactly 2 subquestions with unique IDs
    - Each subquestion has a scoped time constraint targeting it
    - Prevents unscoped constraints from applying globally
    """
    assert "subquestions" in plan, "Plan must have subquestions"
    assert len(plan["subquestions"]) == 2, f"Comparison must have exactly 2 subquestions, got {len(plan['subquestions'])}"
    
    # Get subquestion IDs
    sq_ids = [sq["id"] for sq in plan["subquestions"]]
    assert len(set(sq_ids)) == 2, f"Subquestion IDs must be unique, got {sq_ids}"
    
    # Verify each subquestion has a scoped time constraint targeting it
    assert "constraints" in plan, "Comparison plan must have constraints"
    
    constraints_by_target = {}
    for constraint in plan["constraints"]:
        if constraint.get("type") == "time" and constraint.get("applies_to"):
            target = constraint["applies_to"]
            # Verify applies_to references a real subquestion
            assert target in sq_ids, f"Constraint applies_to='{target}' not in subquestion IDs {sq_ids}"
            constraints_by_target[target] = constraint
    
    # Each subquestion must have a scoped time constraint
    for sq_id in sq_ids:
        assert sq_id in constraints_by_target, (
            f"Subquestion {sq_id} missing scoped time constraint. "
            f"Found constraints for: {list(constraints_by_target.keys())}"
        )


# ============================================================================
# Planner Correctness Tests
# ============================================================================

def test_planner_total_revenue_pure_aggregation():
    """A) Total revenue - pure aggregation without group_by."""
    question = "What is total revenue?"
    schema = "Table: orders\nColumns:\n  - revenue (DOUBLE)"
    
    # Mock LLM to return valid pure aggregation plan
    valid_plan = {
        "original_question": question,
        "subquestions": [
            {
                "id": "SQ1",
                "tables": ["orders"],
                "aggregations": [{"agg": "sum", "col": "revenue"}]
            }
        ]
    }
    
    with patch("haikugraph.planning.llm_planner.classify_intent", return_value=_mock_intent(IntentType.METRIC)), \
         patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.return_value = _fake_llm_return(valid_plan)
        
        plan = generate_or_patch_plan(question=question, schema=schema)
        
        # Validate schema conformance
        validate_plan_or_raise(plan)
        
        # Validate semantic correctness
        _assert_has_pure_aggregation(plan)
        assert plan["original_question"] == question


def test_planner_revenue_by_barber_grouped_aggregation():
    """B) Revenue by barber - grouped aggregation."""
    question = "What is revenue by barber?"
    schema = "Table: appointments\nColumns:\n  - barber_id (VARCHAR)\n  - revenue (DOUBLE)"
    
    valid_plan = {
        "original_question": question,
        "subquestions": [
            {
                "id": "SQ1",
                "tables": ["appointments"],
                "group_by": ["barber_id"],
                "aggregations": [{"agg": "sum", "col": "revenue"}]
            }
        ]
    }
    
    with patch("haikugraph.planning.llm_planner.classify_intent", return_value=_mock_intent(IntentType.METRIC)), \
         patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.return_value = _fake_llm_return(valid_plan)
        
        plan = generate_or_patch_plan(question=question, schema=schema)
        
        validate_plan_or_raise(plan)
        _assert_has_grouped_aggregation(plan)
        assert plan["original_question"] == question

def test_planner_top_5_barbers_grouped_with_row_limit():
    """C) Top 5 barbers by revenue - grouped aggregation + row_limit.
    
    Note: This test enforces row_limit at plan level, which is supported by the
    executor but not explicitly mentioned in planner prompts. Real LLMs may vary.
    The test validates the executor can handle row_limit if provided.
    """
    question = "Who are the top 5 barbers by revenue?"
    schema = "Table: appointments\nColumns:\n  - barber_id (VARCHAR)\n  - revenue (DOUBLE)"
    
    valid_plan = {
        "original_question": question,
        "subquestions": [
            {
                "id": "SQ1",
                "tables": ["appointments"],
                "group_by": ["barber_id"],
                "aggregations": [{"agg": "sum", "col": "revenue"}]
            }
        ],
        "row_limit": 5
    }
    
    with patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.return_value = _fake_llm_return(valid_plan)
        
        plan = generate_or_patch_plan(question=question, schema=schema)
        
        validate_plan_or_raise(plan)
        _assert_has_grouped_aggregation(plan)
        # Flexible assertion: accepts row_limit if present (schema allows extra fields)
        # Real planners may or may not emit this field
        if "row_limit" in plan:
            assert plan["row_limit"] == 5, "If row_limit present, should be 5"


def test_planner_revenue_last_30_days_aggregation_with_time():
    """D) Total revenue last 30 days - aggregation + time constraint."""
    question = "What is total revenue in the last 30 days?"
    schema = "Table: orders\nColumns:\n  - revenue (DOUBLE)\n  - created_at (TIMESTAMP)"
    
    valid_plan = {
        "original_question": question,
        "subquestions": [
            {
                "id": "SQ1",
                "tables": ["orders"],
                "aggregations": [{"agg": "sum", "col": "revenue"}]
            }
        ],
        "constraints": [
            {
                "type": "time",
                "expression": "orders.created_at in last_30_days"
            }
        ]
    }
    
    with patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.return_value = _fake_llm_return(valid_plan)
        
        plan = generate_or_patch_plan(question=question, schema=schema)
        
        validate_plan_or_raise(plan)
        _assert_has_pure_aggregation(plan)
        _assert_has_time_constraint(plan, require_scoped=False)


def test_planner_comparison_this_month_vs_last_month():
    """E) Revenue this month vs last month - comparison with scoped constraints.
    
    Note: Both constraints are scoped to prevent unscoped constraint applying globally.
    The executor applies unscoped constraints to all matching subquestions.
    """
    question = "Compare revenue this month vs last month"
    schema = "Table: orders\nColumns:\n  - revenue (DOUBLE)\n  - created_at (TIMESTAMP)"
    
    valid_plan = {
        "original_question": question,
        "subquestions": [
            {
                "id": "SQ1_current",
                "tables": ["orders"],
                "aggregations": [{"agg": "sum", "col": "revenue"}]
            },
            {
                "id": "SQ2_comparison",
                "tables": ["orders"],
                "aggregations": [{"agg": "sum", "col": "revenue"}]
            }
        ],
        "constraints": [
            {
                "type": "time",
                "expression": "orders.created_at in this_month",
                "applies_to": "SQ1_current"  # Scoped to prevent global application
            },
            {
                "type": "time",
                "expression": "orders.created_at in previous_month",
                "applies_to": "SQ2_comparison"
            }
        ]
    }
    
    with patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.return_value = _fake_llm_return(valid_plan)
        
        plan = generate_or_patch_plan(question=question, schema=schema)
        
        validate_plan_or_raise(plan)
        _assert_is_comparison(plan)


def test_planner_recent_appointments_lookup_no_aggregations():
    """F) Show recent appointments - lookup query without aggregations."""
    question = "Show me recent appointments"
    schema = "Table: appointments\nColumns:\n  - id (VARCHAR)\n  - customer_name (VARCHAR)\n  - appointment_time (TIMESTAMP)"
    
    valid_plan = {
        "original_question": question,
        "subquestions": [
            {
                "id": "SQ1",
                "tables": ["appointments"],
                "columns": ["id", "customer_name", "appointment_time"]
            }
        ],
        "constraints": [
            {
                "type": "time",
                "expression": "appointments.appointment_time in last_7_days"
            }
        ]
    }
    
    with patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.return_value = _fake_llm_return(valid_plan)
        
        plan = generate_or_patch_plan(question=question, schema=schema)
        
        validate_plan_or_raise(plan)
        
        # Verify it's a lookup query (no aggregations)
        for sq in plan["subquestions"]:
            aggregations = sq.get("aggregations")
            assert not aggregations or len(aggregations) == 0, "Lookup query should not have aggregations"
        
        # Should have time constraint
        _assert_has_time_constraint(plan, require_scoped=False)


# ============================================================================
# Repair Loop Test
# ============================================================================

def test_planner_repair_loop_invalid_to_valid():
    """G) LLM repair loop - first returns invalid, then repairs to valid."""
    question = "What is revenue by barber?"
    schema = "Table: appointments\nColumns:\n  - barber_id (VARCHAR)\n  - revenue (DOUBLE)"
    
    # First attempt: invalid plan (group_by with empty aggregations)
    invalid_plan = {
        "original_question": question,
        "subquestions": [
            {
                "id": "SQ1",
                "tables": ["appointments"],
                "group_by": ["barber_id"],
                "aggregations": []  # Invalid: empty when group_by present
            }
        ]
    }
    
    # Second attempt: valid plan (fixed aggregations)
    valid_plan = {
        "original_question": question,
        "subquestions": [
            {
                "id": "SQ1",
                "tables": ["appointments"],
                "group_by": ["barber_id"],
                "aggregations": [{"agg": "sum", "col": "revenue"}]
            }
        ]
    }
    
    call_count = 0
    def mock_llm_with_repair(*args, **kwargs):
        nonlocal call_count
        call_count += 1
        if call_count == 1:
            # First call: return invalid plan
            return _fake_llm_return(invalid_plan)
        else:
            # Repair call: return valid plan
            return _fake_llm_return(valid_plan)
    
    with patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.side_effect = mock_llm_with_repair
        
        plan = generate_or_patch_plan(question=question, schema=schema)
        
        # Should have called LLM twice (initial + repair)
        assert mock_llm.call_count == 2, f"Expected 2 LLM calls (initial + repair), got {mock_llm.call_count}"
        
        # Verify second call was actually a repair prompt (contains error context)
        second_call_messages = mock_llm.call_args_list[1][0][0]  # messages arg from second call
        second_call_content = " ".join(msg["content"] for msg in second_call_messages)
        # Check for repair prompt indicators
        assert "error" in second_call_content.lower() or "fix" in second_call_content.lower(), (
            "Second LLM call should be repair prompt with error context"
        )
        
        # Final plan should be valid
        validate_plan_or_raise(plan)
        
        # Should be grouped aggregation (the intent of the query)
        _assert_has_grouped_aggregation(plan)


# ============================================================================
# Edge Cases
# ============================================================================

def test_planner_handles_markdown_wrapped_json():
    """Planner should handle LLM returning JSON wrapped in markdown code blocks."""
    question = "What is total revenue?"
    schema = "Table: orders\nColumns:\n  - revenue (DOUBLE)"
    
    valid_plan = {
        "original_question": question,
        "subquestions": [
            {
                "id": "SQ1",
                "tables": ["orders"],
                "aggregations": [{"agg": "sum", "col": "revenue"}]
            }
        ]
    }
    
    # Wrap in markdown code block
    markdown_response = f"```json\n{json.dumps(valid_plan, indent=2)}\n```"
    
    with patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.return_value = markdown_response
        
        plan = generate_or_patch_plan(question=question, schema=schema)
        
        validate_plan_or_raise(plan)
        _assert_has_pure_aggregation(plan)


def test_planner_multiple_tables_requires_joins():
    """Plans with multiple tables should be valid (executor handles join logic)."""
    question = "What is total revenue from orders and customers?"
    schema = "Table: orders\nColumns:\n  - revenue (DOUBLE)\n  - customer_id (VARCHAR)\nTable: customers\nColumns:\n  - id (VARCHAR)"
    
    valid_plan = {
        "original_question": question,
        "subquestions": [
            {
                "id": "SQ1",
                "tables": ["orders", "customers"],
                "aggregations": [{"agg": "sum", "col": "revenue"}]
            }
        ],
        "join_paths": [
            {
                "from": "orders",
                "to": "customers",
                "via": ["customer_id"]
            }
        ]
    }
    
    with patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.return_value = _fake_llm_return(valid_plan)
        
        plan = generate_or_patch_plan(question=question, schema=schema)
        
        validate_plan_or_raise(plan)
        assert len(plan["subquestions"][0]["tables"]) == 2, "Should have 2 tables"


def test_planner_fails_after_max_retries_with_junk():
    """H) Planner raises ValueError when LLM returns junk after all retries."""
    question = "What is total revenue?"
    schema = "Table: orders\nColumns:\n  - revenue (DOUBLE)"
    
    # LLM always returns unparseable junk
    junk_response = "This is not JSON at all! Just random text."
    
    with patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.return_value = junk_response
        
        # Should raise ValueError after exhausting retries
        with pytest.raises(ValueError) as exc_info:
            generate_or_patch_plan(question=question, schema=schema)
        
        error_msg = str(exc_info.value)
        
        # Verify error message contains retry info and last error
        assert "retries" in error_msg.lower(), "Error should mention retries"
        assert "2" in error_msg or "max" in error_msg.lower(), "Error should reference max retries (2)"
        # Should contain parse error info
        assert "json" in error_msg.lower() or "parse" in error_msg.lower(), (
            "Error should mention JSON parsing failure"
        )
        
        # Should have attempted initial + max_retries (default 2)
        assert mock_llm.call_count == 3, f"Expected 3 LLM calls (initial + 2 repairs), got {mock_llm.call_count}"


def test_planner_fails_after_max_retries_with_invalid_plan():
    """I) Planner raises ValueError when LLM returns schema-invalid plan after all retries."""
    question = "What is total revenue?"
    schema = "Table: orders\nColumns:\n  - revenue (DOUBLE)"
    
    # Always return plan missing required field
    invalid_plan = {
        # Missing original_question!
        "subquestions": [
            {
                "id": "SQ1",
                "tables": ["orders"],
                "aggregations": [{"agg": "sum", "col": "revenue"}]
            }
        ]
    }
    
    with patch("haikugraph.planning.llm_planner.call_llm") as mock_llm:
        mock_llm.return_value = _fake_llm_return(invalid_plan)
        
        # Should raise ValueError after exhausting retries
        with pytest.raises(ValueError) as exc_info:
            generate_or_patch_plan(question=question, schema=schema)
        
        error_msg = str(exc_info.value)
        
        # Verify error message contains validation failure info
        assert "validation" in error_msg.lower() or "invalid" in error_msg.lower(), (
            "Error should mention validation failure"
        )
        assert "retries" in error_msg.lower(), "Error should mention retries"
        assert "original_question" in error_msg, "Error should mention the missing field"
        
        # Should have attempted initial + max_retries (default 2)
        assert mock_llm.call_count == 3, f"Expected 3 LLM calls (initial + 2 repairs), got {mock_llm.call_count}"
